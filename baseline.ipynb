{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\geral\\miniconda3\\envs\\AV\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from Dataset.CustomDataset import AgeGroupAndAgeDataset, StandardDataset, AgeGroupAndAgeDatasetKL\n",
    "from Dataset.CustomDataLoaders import CustomDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from Utils import AAR, CSVUtils, AgeConversion\n",
    "from Utils.Validator import Validator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caricamento del dataframe\n",
    "df = CSVUtils.get_df_from_csv(\"./training_caip_contest.csv\", \"./training_caip_contest/\")\n",
    "\n",
    "#Suddivisione del dataframe in 3 age groups\n",
    "_, d = CSVUtils.get_df_with_age_subdivision(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting tra Train e Validation set\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=42)\n",
    "#Aggiornamento degli indici per pandas\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "transform_func = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.RandomGrayscale(),\n",
    "])\n",
    "\n",
    "transform_func_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "#Implementazione di un Dataset utilizzando \"CustomDataset\" per l'architettura con Film\n",
    "cd_train = AgeGroupAndAgeDatasetKL(df_train, path_col=\"path\", label_col=\"age\", label_function=\"CAE\", \n",
    "                                 label_map=d, label_map_n_classes=3, transform_func=transform_func)\n",
    "\n",
    "#Implementazione di un Dataset che adatta le label all'utilizzo che vogliamo farne (in questo caso CAE = Cathegorical)\n",
    "cd_val = StandardDataset(df_val, path_col=\"path\", label_col=\"age\", label_function=\"CAE\", transform_func=transform_func_val)\n",
    "\n",
    "#Dato che lo split potrebbe non prendere sample di determinate classi facciamo il set del numero di classi\n",
    "cd_train.set_n_classes(101)\n",
    "\n",
    "#Loader che, conoscendo la grandezza del dataset, farà lo shuffle dei campioni e crea i batch\n",
    "dm_train, dm_val = CustomDataLoader(cd_train), CustomDataLoader(cd_val)\n",
    "#Utilizziamo il dataloader che crea batch bilanciati implementato in CustomDataLoaders\n",
    "# In generale non usare questo ma l'unbalanced dato che non è usato in nessun doc\n",
    "dl_train = dm_train.get_unbalanced_dataloader(batch_size=128 ,shuffle=True, num_workers=6, prefetch_factor=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Initialize the ResNet18 model with pre-trained parameters on ImageNet\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "# Change the dimension of the fully connected layer to K\n",
    "K = 101\n",
    "model.fc = nn.Linear(model.fc.in_features, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validator che si occuperà di tenere in considerazione le metriche da massimizzare per il contest\n",
    "validator = Validator(cd_val, AgeConversion.ArgMaxAge, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transformation that resizes the image and flips it horizontally with a probability of 0.5\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KL divergence loss\n",
    "def kl_divergence_loss(pred, target):\n",
    "    # Calculate the KL divergence between the label distribution and the predicted age distribution\n",
    "    loss = nn.KLDivLoss(reduction='batchmean')(pred.log(), target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Define the L1 loss\n",
    "def l1_loss(pred, target):\n",
    "    # Calculate the L1 loss between the predicted age and the ground truth label\n",
    "    loss = nn.L1Loss()(pred, target)\n",
    "    return loss\n",
    "\n",
    "# Combine the KL divergence loss and L1 loss\n",
    "def combined_loss(pred, target):\n",
    "    return kl_divergence_loss(pred, target) + l1_loss(pred, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [29:37<00:00,  1.90 batch/s, loss=1.550241681114393] \n",
      "100%|██████████| 1124/1124 [11:26<00:00,  1.64 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7332) tensor(3.2873)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [27:02<00:00,  2.08 batch/s, loss=1.5913941467935568]\n",
      "100%|██████████| 1124/1124 [06:03<00:00,  3.09 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8389) tensor(3.5043)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [26:10<00:00,  2.15 batch/s, loss=1.3799243464590971]\n",
      "100%|██████████| 1124/1124 [05:51<00:00,  3.20 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8280) tensor(3.9404)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [25:55<00:00,  2.17 batch/s, loss=1.2814616227887252]\n",
      "100%|██████████| 1124/1124 [05:47<00:00,  3.23 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3062) tensor(4.2741)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [26:05<00:00,  2.15 batch/s, loss=1.4452313129793148]\n",
      "100%|██████████| 1124/1124 [05:49<00:00,  3.22 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3052) tensor(4.2903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [26:19<00:00,  2.13 batch/s, loss=1.1852652929740393]\n",
      "100%|██████████| 1124/1124 [05:51<00:00,  3.20 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1249) tensor(4.1482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [25:29<00:00,  2.20 batch/s, loss=1.380918563752509] \n",
      "100%|██████████| 1124/1124 [05:58<00:00,  3.14 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8820) tensor(4.5617)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [26:17<00:00,  2.14 batch/s, loss=1.2774677652363395]\n",
      "100%|██████████| 1124/1124 [05:49<00:00,  3.22 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9958) tensor(4.7356)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [26:08<00:00,  2.15 batch/s, loss=1.320111941851504] \n",
      "100%|██████████| 1124/1124 [05:47<00:00,  3.24 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9632) tensor(4.7728)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [24:26<00:00,  2.30 batch/s, loss=1.37745122997859]  \n",
      "100%|██████████| 1124/1124 [05:43<00:00,  3.27 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2664) tensor(4.9828)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [24:52<00:00,  2.26 batch/s, loss=1.3061048887902151]\n",
      "100%|██████████| 1124/1124 [06:00<00:00,  3.12 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9983) tensor(4.7992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [24:24<00:00,  2.30 batch/s, loss=1.0694381833196762]\n",
      "100%|██████████| 1124/1124 [05:47<00:00,  3.23 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9797) tensor(4.7391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [25:35<00:00,  2.19 batch/s, loss=1.1617215321009176]\n",
      "100%|██████████| 1124/1124 [05:42<00:00,  3.28 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9322) tensor(5.4152)\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [24:24<00:00,  2.30 batch/s, loss=1.1989155125754247]\n",
      "100%|██████████| 1124/1124 [05:40<00:00,  3.30 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6992) tensor(5.2669)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [27:05<00:00,  2.07 batch/s, loss=1.0663645169928682]\n",
      "100%|██████████| 1124/1124 [08:45<00:00,  2.14 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0498) tensor(4.8838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [29:38<00:00,  1.89 batch/s, loss=1.0724023157030758]\n",
      "100%|██████████| 1124/1124 [05:48<00:00,  3.23 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5113) tensor(5.2133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [27:32<00:00,  2.04 batch/s, loss=1.1447826310447502]\n",
      "100%|██████████| 1124/1124 [05:56<00:00,  3.15 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8884) tensor(5.4632)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 447/3370 [03:51<25:12,  1.93 batch/s, loss=1.1788868882977528] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(dl_train, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m batch\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tepoch:\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m, target \u001b[39min\u001b[39;00m tepoch:\n\u001b[0;32m     17\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m         target \u001b[39m=\u001b[39m target[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "best_val_aar = -1\n",
    "# Define the optimization algorithm\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40, 60], gamma=0.1)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "# Train the model for a total of 75 epochs\n",
    "for epoch in range(75):\n",
    "    # Train the model on the training data\n",
    "    model.train()\n",
    "    with tqdm(dl_train, unit=\" batch\") as tepoch:\n",
    "        for input, target in tepoch:\n",
    "            input = input.to(\"cuda\")\n",
    "            target = target[-1].to(\"cuda\")\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = F.softmax(model(input), dim=-1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = combined_loss(output, target)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            tepoch.set_postfix(loss=loss.detach().cpu().numpy()) \n",
    "        \n",
    "    # Decrease the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    def forward_function(x):\n",
    "        return F.softmax(model(x), dim=-1)\n",
    "\n",
    "    val_aar, val_aar_old = validator.validate(forward_function)\n",
    "    print(val_aar, val_aar_old)\n",
    "\n",
    "    if val_aar > best_val_aar:\n",
    "        best_val_aar = val_aar\n",
    "        torch.save(model.state_dict(), \"./model_age_baseline.pt\")\n",
    "        print(\"Model saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eaf4869da21e1db72c76fb1a3d42f0021933429756275c00fff16629dcda963c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
