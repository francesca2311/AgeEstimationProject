{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from Dataset.CustomDataset import AgeGroupAndAgeDataset, StandardDataset, AgeDatasetKL\n",
    "from Dataset.CustomDataLoaders import CustomDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from Utils import AAR, CSVUtils, AgeConversion\n",
    "from Utils.Validator import Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "import pandas as pd\n",
    "df = CSVUtils.get_df_from_csv(\"./training_caip_contest.csv\", \"./training_caip_contest/\")\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=42)\n",
    "aug = CSVUtils.get_df_from_csv(\"./augumentation_balanced_remove.csv\", \"./newAugmentationDataset/\")\n",
    "df_train_aug = pd.concat([df_train, aug], ignore_index=True)\n",
    "df_train_aug = df_train_aug.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "#########################\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "transform_func = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.RandAugment(2, 9),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_func_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Implementazione di un Dataset utilizzando \"CustomDataset\" per l'architettura con Film\n",
    "cd_train_balanced = AgeDatasetKL(df_train_aug, path_col=\"path\", label_col=\"age\", label_function=\"Linear\", \n",
    "                                transform_func=transform_func)\n",
    "cd_train_balanced.set_n_classes(81)\n",
    "cd_train_balanced.set_starting_class(1)\n",
    "dm_train_balanced = CustomDataLoader(cd_train_balanced)\n",
    "dl_train_balanced, sampler = dm_train_balanced.get_balanced_class_dataloader2(class_ranges=[(0, 11), (11, 21), (21, 31), (31, 41), (41, 51), (51, 61), (61, 71), (71, 91)], \n",
    "                                                                            batch_size=64, num_workers=1, prefetch_factor=2)\n",
    "sampler.n_batches = 10\n",
    "sampler.p = np.array([0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "cd_val = StandardDataset(df_val, path_col=\"path\", label_col=\"age\", label_function=\"CAE\", transform_func=transform_func_val)\n",
    "cd_val.set_n_classes(81)\n",
    "cd_val.set_starting_class(1)\n",
    "validator = Validator(cd_val, AgeConversion.EVAge, 32, num_workers=4, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.4739, -0.5767, -0.6452,  ..., -0.0287,  0.0741,  0.1083],\n",
      "          [-0.5767, -0.7137, -0.7479,  ..., -0.0629,  0.0398,  0.1083],\n",
      "          [-0.6794, -0.7479, -0.8164,  ..., -0.0629,  0.0398,  0.1083],\n",
      "          ...,\n",
      "          [-0.3369, -0.4397, -0.4739,  ...,  1.2043,  1.1358,  1.0673],\n",
      "          [-0.1999, -0.3369, -0.4397,  ...,  1.1358,  1.0673,  1.0331],\n",
      "          [-0.1314, -0.2342, -0.3369,  ...,  1.1015,  1.0673,  0.9646]],\n",
      "\n",
      "         [[-1.0203, -1.1253, -1.1954,  ..., -0.7052, -0.6352, -0.6001],\n",
      "          [-1.1253, -1.2654, -1.3004,  ..., -0.7402, -0.6702, -0.6001],\n",
      "          [-1.1604, -1.2654, -1.3354,  ..., -0.7402, -0.6702, -0.6001],\n",
      "          ...,\n",
      "          [-0.8803, -0.9503, -1.0553,  ...,  0.4853,  0.3803,  0.3102],\n",
      "          [-0.7752, -0.8803, -0.9503,  ...,  0.4153,  0.3452,  0.2752],\n",
      "          [-0.6702, -0.7752, -0.8803,  ...,  0.3803,  0.3102,  0.2402]],\n",
      "\n",
      "         [[-1.1770, -1.2816, -1.3513,  ..., -1.1073, -1.0376, -0.9678],\n",
      "          [-1.2467, -1.3861, -1.4559,  ..., -1.1421, -1.0724, -1.0027],\n",
      "          [-1.2816, -1.4210, -1.4559,  ..., -1.1421, -1.0724, -1.0027],\n",
      "          ...,\n",
      "          [-1.1073, -1.2119, -1.2816,  ...,  0.0779,  0.0431,  0.0082],\n",
      "          [-1.0027, -1.1073, -1.2119,  ...,  0.0431,  0.0082,  0.0082],\n",
      "          [-0.8981, -1.0376, -1.1073,  ...,  0.0082, -0.0267, -0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3138,  0.3138,  0.3823,  ..., -1.5185, -1.5528, -1.5528],\n",
      "          [ 0.3138,  0.3138,  0.3823,  ..., -1.5185, -1.5528, -1.5528],\n",
      "          [ 0.2967,  0.2967,  0.3652,  ..., -1.5185, -1.5528, -1.5528],\n",
      "          ...,\n",
      "          [-1.2445, -1.2445, -1.2445,  ..., -0.0801, -0.0116, -0.0116],\n",
      "          [-1.3130, -1.3130, -1.3130,  ..., -0.0801, -0.0116, -0.0116],\n",
      "          [-1.3130, -1.3130, -1.3130,  ..., -0.0801, -0.0116, -0.0116]],\n",
      "\n",
      "         [[-1.4755, -1.4755, -1.4930,  ..., -1.6856, -1.7031, -1.7031],\n",
      "          [-1.4755, -1.4755, -1.4930,  ..., -1.6856, -1.7031, -1.7031],\n",
      "          [-1.5280, -1.5280, -1.5280,  ..., -1.6856, -1.7031, -1.7031],\n",
      "          ...,\n",
      "          [-1.2829, -1.2829, -1.3179,  ..., -0.4776, -0.4076, -0.4076],\n",
      "          [-1.3354, -1.3354, -1.3354,  ..., -0.4776, -0.4076, -0.4076],\n",
      "          [-1.3354, -1.3354, -1.3354,  ..., -0.4776, -0.4076, -0.4076]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.5430, -1.5604, -1.5604],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.5430, -1.5604, -1.5604],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.5430, -1.5604, -1.5604],\n",
      "          ...,\n",
      "          [-1.5430, -1.5430, -1.5430,  ..., -0.7413, -0.6890, -0.6890],\n",
      "          [-1.6127, -1.6127, -1.5779,  ..., -0.7413, -0.6890, -0.6890],\n",
      "          [-1.6127, -1.6127, -1.5779,  ..., -0.7413, -0.6890, -0.6890]]],\n",
      "\n",
      "\n",
      "        [[[-1.7754, -1.8439, -1.9124,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.7754, -1.8439, -1.9124,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.7925, -1.8610, -1.9295,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-1.9467, -1.9638, -1.9638,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.9467, -1.9467, -1.9467,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.9467, -1.9467, -1.9467,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-1.6856, -1.7556, -1.8081,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-1.6856, -1.7556, -1.8081,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-1.7031, -1.7556, -1.8256,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-1.8957, -1.9132, -1.9132,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-1.8957, -1.8957, -1.8957,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-1.8957, -1.8957, -1.8957,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.4559, -1.5256, -1.5779,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.4559, -1.5256, -1.5779,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.4733, -1.5256, -1.5953,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.6650, -1.6824, -1.6824,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.6650, -1.6650, -1.6650,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.6650, -1.6650, -1.6650,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5014, -1.5014, -1.5185,  ..., -0.8507, -0.9020, -0.9192],\n",
      "          [-1.5014, -1.5014, -1.5185,  ..., -0.8507, -0.9020, -0.9192],\n",
      "          [-1.5014, -1.5185, -1.5528,  ..., -0.8507, -0.9534, -0.9534],\n",
      "          ...,\n",
      "          [-1.5699, -1.5528, -1.5185,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.5528, -1.5185, -1.5014,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-1.5528, -1.5185, -1.5014,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-1.9657, -1.9657, -1.9832,  ...,  2.3060,  2.2885,  2.2710],\n",
      "          [-1.9657, -1.9657, -1.9832,  ...,  2.3235,  2.2885,  2.2710],\n",
      "          [-1.9657, -1.9832, -2.0007,  ...,  2.3410,  2.2885,  2.2885],\n",
      "          ...,\n",
      "          [-0.7752, -0.7752, -0.7752,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.7577, -0.7577, -0.7577,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.7577, -0.7577, -0.7577,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-0.7936, -0.7936, -0.8110,  ..., -0.3753, -0.4101, -0.4275],\n",
      "          [-0.7936, -0.7936, -0.8110,  ..., -0.3753, -0.4101, -0.4275],\n",
      "          [-0.7936, -0.8110, -0.8284,  ..., -0.3927, -0.4275, -0.4275],\n",
      "          ...,\n",
      "          [ 0.0953,  0.0779,  0.0779,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 0.1128,  0.0953,  0.0953,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 0.1128,  0.0953,  0.0953,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.0398,  0.0741,  0.0912],\n",
      "          [ 0.5022,  0.4679,  0.4851,  ...,  0.0741,  0.0741,  0.0912],\n",
      "          [ 0.4508,  0.4337,  0.4679,  ...,  0.1426,  0.1254,  0.1768]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 0.6604,  0.6779,  0.6954,  ...,  0.1877,  0.2227,  0.2402],\n",
      "          [ 0.6254,  0.6429,  0.6779,  ...,  0.2227,  0.2227,  0.2402],\n",
      "          [ 0.6078,  0.6078,  0.6604,  ...,  0.2402,  0.2402,  0.2752]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 0.0605,  0.0431,  0.0256,  ..., -0.4798, -0.4450, -0.4275],\n",
      "          [ 0.0431,  0.0082,  0.0256,  ..., -0.4450, -0.4450, -0.4275],\n",
      "          [ 0.0082, -0.0092, -0.0092,  ..., -0.4101, -0.4275, -0.3927]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2453,  0.2967,  0.2796,  ..., -0.6281, -0.5596, -0.5253],\n",
      "          [ 0.2967,  0.2967,  0.2453,  ..., -0.6281, -0.5767, -0.5767],\n",
      "          [ 0.3309,  0.2967,  0.2282,  ..., -0.6452, -0.5938, -0.5938],\n",
      "          ...,\n",
      "          [ 0.2796,  0.2796,  0.2967,  ...,  0.0398,  0.0398,  0.0398],\n",
      "          [ 0.2967,  0.2796,  0.2796,  ...,  0.0741,  0.0741,  0.0741],\n",
      "          [ 0.2796,  0.2967,  0.3309,  ...,  0.0741,  0.0741,  0.0741]],\n",
      "\n",
      "         [[-0.3375, -0.2850, -0.3025,  ..., -1.1954, -1.1429, -1.1078],\n",
      "          [-0.2850, -0.2850, -0.3375,  ..., -1.1954, -1.1604, -1.1604],\n",
      "          [-0.2325, -0.2850, -0.3375,  ..., -1.2129, -1.1954, -1.1954],\n",
      "          ...,\n",
      "          [-0.1625, -0.2325, -0.2850,  ..., -0.4951, -0.4951, -0.5301],\n",
      "          [-0.1450, -0.1975, -0.2500,  ..., -0.4776, -0.4951, -0.4951],\n",
      "          [-0.1625, -0.1625, -0.2500,  ..., -0.4776, -0.4776, -0.4951]],\n",
      "\n",
      "         [[-0.1661, -0.1138, -0.1312,  ..., -1.0027, -0.8458, -0.8110],\n",
      "          [-0.1138, -0.1138, -0.1661,  ..., -1.0550, -0.9156, -0.8458],\n",
      "          [-0.0790, -0.1138, -0.1835,  ..., -1.0898, -0.8981, -0.8633],\n",
      "          ...,\n",
      "          [-0.1138, -0.0790, -0.1138,  ..., -0.2707, -0.1661, -0.1312],\n",
      "          [-0.0790, -0.1138, -0.0790,  ..., -0.2184, -0.1312, -0.1138],\n",
      "          [-0.1138, -0.0790, -0.0790,  ..., -0.2358, -0.1312, -0.1138]]]]), [tensor([59, 56, 27, 28,  7,  6, 67, 23,  0,  6,  7,  5, 61, 47, 56, 57, 74,  0,\n",
      "        46, 26, 34,  5, 28, 50, 68, 33, 71,  0,  6, 13, 46,  8,  9, 42,  8, 16,\n",
      "        47, 68,  2, 53, 78, 56, 45, 46, 51, 32,  4, 68,  6, 30, 66, 65, 15, 80,\n",
      "         8, 49, 54,  3,  0, 52,  1, 27,  6,  9]), tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.6246e-79,\n",
      "          5.5209e-88,  6.9020e-97],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., 3.1743e-106,\n",
      "         5.3706e-116, 3.3427e-126],\n",
      "        [1.9979e-159, 6.4473e-148, 7.6539e-137,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [1.9979e-159, 6.4473e-148, 7.6539e-137,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.0759e-09,  1.4867e-06,  1.3383e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0280e-18,  5.0523e-15,  9.1347e-12,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], dtype=torch.float64)]]\n"
     ]
    }
   ],
   "source": [
    "for d in dl_train_balanced:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([59, 56, 27, 28,  7,  6, 67, 23,  0,  6,  7,  5, 61, 47, 56, 57, 74,  0,\n",
      "        46, 26, 34,  5, 28, 50, 68, 33, 71,  0,  6, 13, 46,  8,  9, 42,  8, 16,\n",
      "        47, 68,  2, 53, 78, 56, 45, 46, 51, 32,  4, 68,  6, 30, 66, 65, 15, 80,\n",
      "         8, 49, 54,  3,  0, 52,  1, 27,  6,  9])\n",
      "tensor([59., 56., 27., 28.,  7.,  6., 67., 23.,  1.,  6.,  7.,  5., 61., 47.,\n",
      "        56., 57., 74.,  1., 46., 26., 34.,  5., 28., 50., 68., 33., 71.,  1.,\n",
      "         6., 13., 46.,  8.,  9., 42.,  8., 16., 47., 68.,  2., 53., 78., 56.,\n",
      "        45., 46., 51., 32.,  4., 68.,  6., 30., 66., 65., 15., 79.,  8., 49.,\n",
      "        54.,  3.,  1., 52.,  1., 27.,  6.,  9.], dtype=torch.float64)\n",
      "tensor([59.0000, 56.0000, 27.0000, 28.0000,  7.0000,  6.0000, 67.0000, 23.0000,\n",
      "         0.5201,  6.0000,  7.0000,  5.0000, 61.0000, 47.0000, 56.0000, 57.0000,\n",
      "        74.0000,  0.5201, 46.0000, 26.0000, 34.0000,  5.0000, 28.0000, 50.0000,\n",
      "        68.0000, 33.0000, 71.0000,  0.5201,  6.0000, 13.0000, 46.0000,  8.0000,\n",
      "         9.0000, 42.0000,  8.0000, 16.0000, 47.0000, 68.0000,  2.0139, 53.0000,\n",
      "        77.9861, 56.0000, 45.0000, 46.0000, 51.0000, 32.0000,  4.0000, 68.0000,\n",
      "         6.0000, 30.0000, 66.0000, 65.0000, 15.0000, 79.4799,  8.0000, 49.0000,\n",
      "        54.0000,  3.0005,  0.5201, 52.0000,  1.1294, 27.0000,  6.0000,  9.0000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(d[1][0])\n",
    "t: torch.Tensor = d[1][1]\n",
    "# t.sum(dim=-1)\n",
    "print(torch.round(AgeConversion.EVAge(d[1][1])))\n",
    "print(AgeConversion.EVAge(d[1][1] / t.sum(dim=-1, keepdim=True).expand(-1, 81)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 81])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468, 0.99986468, 0.99986468, 0.99986468, 0.99986468,\n",
       "       0.99986468])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.sum(t.numpy(), axis=-1, keepdims=True), (1, 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _to_kl_labels(y, n_classes):\n",
    "    std = 1.0\n",
    "    _y = np.arange(n_classes)\n",
    "    return 1/(std * np.sqrt(2*np.pi)) * np.exp(-np.square(_y-y) / (2*std**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = _to_kl_labels(1, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.41970725e-001, 3.98942280e-001, 2.41970725e-001, 5.39909665e-002,\n",
       "       4.43184841e-003, 1.33830226e-004, 1.48671951e-006, 6.07588285e-009,\n",
       "       9.13472041e-012, 5.05227108e-015, 1.02797736e-018, 7.69459863e-023,\n",
       "       2.11881925e-027, 2.14638374e-032, 7.99882776e-038, 1.09660656e-043,\n",
       "       5.53070955e-050, 1.02616307e-056, 7.00418213e-064, 1.75874954e-071,\n",
       "       1.62463604e-079, 5.52094836e-088, 6.90202942e-097, 3.17428155e-106,\n",
       "       5.37056037e-116, 3.34271444e-126, 7.65392974e-137, 6.44725997e-148,\n",
       "       1.99788926e-159, 2.27757748e-171, 9.55169454e-184, 1.47364613e-196,\n",
       "       8.36395161e-210, 1.74636626e-223, 1.34141967e-237, 3.79052640e-252,\n",
       "       3.94039628e-267, 1.50690472e-282, 2.12000655e-298, 1.09722105e-314,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1294], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgeConversion.EVAge(torch.unsqueeze(torch.tensor(_to_kl_labels(1, 81)), dim=0) / torch.unsqueeze(torch.tensor(_to_kl_labels(1, 81)), dim=0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3638], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgeConversion.EVAge(torch.unsqueeze(torch.tensor(_to_kl_labels(0, 81)), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ResNetFilmed.resnet import ResNetFiLMed, BackBone, ResNetNotFiLMed, DoNothingLayer\n",
    "from torchvision.models import resnet18, ResNet18_Weights, efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "####################################################\n",
    "EPOCHS = 24\n",
    "####################################################\n",
    "\n",
    "backbone = resnet18(ResNet18_Weights.IMAGENET1K_V1)\n",
    "backbone.fc = DoNothingLayer()\n",
    "backbone.train()\n",
    "backbone.requires_grad_(True)\n",
    "backbone.to(\"cuda\")\n",
    "model_age = ResNetNotFiLMed(backbone, 81)\n",
    "model_age.load_state_dict(torch.load(\"./model_age_classification_simple.pt\", map_location=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/4493 [00:12<4:12:56,  3.38s/ batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39., dtype=torch.float64) tensor(43.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 716/4493 [00:36<03:11, 19.76 batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(out, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m----> 6\u001b[0m ae, mae, val_aar, val_aar_old \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39;49mvalidate_ext2(forward_function)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(ae, mae, val_aar, val_aar_old)\n",
      "File \u001b[1;32me:\\Studio\\Magistrale\\AV\\AgeEstimationProject\\Utils\\Validator.py:142\u001b[0m, in \u001b[0;36mValidator.validate_ext2\u001b[1;34m(self, forward_function)\u001b[0m\n\u001b[0;32m    139\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m out \u001b[39m=\u001b[39m forward_function(x)\n\u001b[0;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m y_real, y_pred \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_function(y), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_function(out)):\n\u001b[0;32m    145\u001b[0m     y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mround(y_pred)\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mforward_function\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_function\u001b[39m(x):\n\u001b[1;32m----> 2\u001b[0m     out \u001b[39m=\u001b[39m model_age(x)\n\u001b[0;32m      3\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(out, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Studio\\Magistrale\\AV\\AgeEstimationProject\\ResNetFilmed\\resnet.py:157\u001b[0m, in \u001b[0;36mResNetNotFiLMed.forward\u001b[1;34m(self, x, knowledge)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, knowledge\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 157\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(x)\n\u001b[0;32m    158\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc0(out)\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torchvision\\models\\resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n\u001b[1;32m---> 97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     identity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample(x)\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Gio\\.conda\\envs\\AV_project\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    149\u001b[0m     \u001b[39m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_batches_tracked\u001b[39m.\u001b[39;49madd_(\u001b[39m1\u001b[39;49m)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    152\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    153\u001b[0m             exponential_average_factor \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def forward_function(x):\n",
    "    out = model_age(x)\n",
    "    out = F.softmax(out, dim=-1)\n",
    "    return out\n",
    "\n",
    "ae, mae, val_aar, val_aar_old = validator.validate_ext2(forward_function)\n",
    "print(ae, mae, val_aar, val_aar_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_centers(outs, ys, old):\n",
    "    centers_for_age = {x: [] for x in range(81)}\n",
    "\n",
    "    for out, y in zip(outs, ys):\n",
    "        for _out, _y in zip(out, y):\n",
    "            centers_for_age[int(_y)].append(_out.detach().cpu().numpy())\n",
    "\n",
    "    for i in centers_for_age:\n",
    "        if len(centers_for_age[i]) > 0:\n",
    "            centers_for_age[i] = torch.tensor(np.array(centers_for_age[i])).mean(dim=0).to(\"cuda\")\n",
    "        else:\n",
    "            centers_for_age[i] = old[i]\n",
    "    return centers_for_age\n",
    "\n",
    "def update_centers(old, new, alpha=0.5):\n",
    "    for i in new:\n",
    "        new[i] = new[i] - alpha*(new[i] - old[i])\n",
    "    return new\n",
    "\n",
    "def get_centers_loss(out, y, centers_for_age):\n",
    "    loss = None\n",
    "    for _out, _y in zip(out, y):\n",
    "        if loss is None:\n",
    "            loss = torch.mean(torch.square(_out - centers_for_age[int(_y)]))\n",
    "        else:    \n",
    "            loss += torch.mean(torch.square(_out - centers_for_age[int(_y)]))\n",
    "    return loss.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233 batch [01:47,  2.20 batch/s, loss_age=2.5409758, loss_age_bal=2.5297728, loss_age_kl=1.2492404040357374, loss_age_kl_bal=1.21976906498012, loss_repr=0.61008906, loss_repr_bal=0.5650206, total_loss=6.465754131539128]   "
     ]
    }
   ],
   "source": [
    "centers_for_age = {x: torch.zeros(size=(512,), device=\"cuda\") for x in range(81)}\n",
    "best_val_aar = val_aar\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    with tqdm(zip(dl_train, dl_train_balanced), unit=\" batch\") as tepoch:\n",
    "        for batch, batch_balanced in tepoch:\n",
    "            opt.zero_grad()\n",
    "            x, y = batch\n",
    "            x_bal, y_bal = batch_balanced\n",
    "\n",
    "            x = x.to(\"cuda\")\n",
    "            y_age: torch.Tensor = y[0].to(\"cuda\")\n",
    "            y_age_kl: torch.Tensor = y[1].to(\"cuda\")\n",
    "\n",
    "            x_bal = x_bal.to(\"cuda\")\n",
    "            y_age_bal: torch.Tensor = y_bal[0].to(\"cuda\")\n",
    "            y_age_kl_bal: torch.Tensor = y_bal[1].to(\"cuda\")\n",
    "\n",
    "            out_rep, out_age = model_age.forward_with_repr(x)\n",
    "            loss_age_kl: torch.Tensor = kl(F.log_softmax(out_age, dim=-1), y_age_kl)\n",
    "            out_age = F.softmax(out_age, dim=-1)\n",
    "            out = AgeConversion.EVAge(out_age).to(\"cuda\")\n",
    "            loss_age = torch.mean(torch.abs(y_age - out))\n",
    "            loss = loss_age_kl + loss_age\n",
    "\n",
    "            out_rep_bal, out_age_bal = model_age.forward_with_repr(x_bal)\n",
    "            loss_age_kl_bal: torch.Tensor = kl(F.log_softmax(out_age_bal, dim=-1), y_age_kl_bal)\n",
    "            out_age_bal = F.softmax(out_age_bal, dim=-1)\n",
    "            out_bal = AgeConversion.EVAge(out_age_bal).to(\"cuda\")\n",
    "            loss_age_bal = torch.mean(torch.abs(y_age_bal - out_bal))\n",
    "            loss_bal = loss_age_kl_bal + torch.square(loss_age_bal - 2.0)\n",
    "\n",
    "            loss_repr = get_centers_loss(out_rep, y_age, centers_for_age)\n",
    "            loss_repr_bal = get_centers_loss(out_rep_bal, y_age_bal, centers_for_age)\n",
    "\n",
    "            total_loss = loss + loss_bal + loss_repr + loss_repr_bal\n",
    "\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            centers_for_age = update_centers(centers_for_age, get_centers((out_rep, out_rep_bal), (y_age, y_age_bal), centers_for_age), alpha=0.5)\n",
    "\n",
    "            tepoch.set_postfix(loss_age_kl=loss_age_kl.detach().cpu().numpy(), loss_age=loss_age.detach().cpu().numpy(),\n",
    "                                loss_age_kl_bal=loss_age_kl_bal.detach().cpu().numpy(), loss_age_bal=loss_age_bal.detach().cpu().numpy(),\n",
    "                                loss_repr=loss_repr.detach().cpu().numpy(), loss_repr_bal=loss_repr_bal.detach().cpu().numpy(),\n",
    "                                total_loss=total_loss.detach().cpu().numpy())\n",
    "\n",
    "    def forward_function(x):\n",
    "        out = model_age(x)\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        return out\n",
    " \n",
    "    ae, mae_, val_aar, val_aar_old = validator.validate_ext2(forward_function)\n",
    "    print(ae, mae_, val_aar, val_aar_old)\n",
    "\n",
    "    if best_val_aar < val_aar:\n",
    "        best_val_aar = val_aar\n",
    "        torch.save(model_age.state_dict(), \"./model_age_feature_simple_no_loss.pt\")\n",
    "        print(\"Saved model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AV_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb944c2b40f40877ef78d83ae6cee61e5f12ef7b90668598de820bc310ff39a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
